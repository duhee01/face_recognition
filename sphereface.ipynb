{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8773bcd0",
   "metadata": {},
   "source": [
    "### Loss_ASoftmax\n",
    "이 함수는 softmax 손실 함수를 수정하여 분류 모델에서의 효과를 높이기 위해 사용됩니다.\n",
    "함수는 입력으로 특징 벡터(x), 레이블(y), 스케일 하이퍼파라미터(l), 클래스 수(num_cls), 마진(m)과 이름(name)을 받습니다. 이 함수에서는 가중치 행렬(w)을 선언하고, A-softmax 손실을 계산합니다.\n",
    "#### 계산\n",
    "가중치 행렬과 특징 벡터를 곱하여 로짓(logits)을 계산합니다.\n",
    "로짓을 특정 기준으로 변환합니다. 여기에서는 A-softmax에서 제안된 방법을 사용합니다. 이 방법은 로짓 벡터를 단위 벡터로 변환하여 각 클래스와의 거리를 측정하고, 이 거리에 스케일 하이퍼파라미터(l)을 곱합니다. 그리고 거리를 각도(cosine)로 변환합니다. 이를 통해 로짓 벡터의 스케일이 잘 조정됩니다.\n",
    "변환된 로짓을 사용하여 손실을 계산합니다. 여기에서는 A-softmax의 변형 중 하나인 additive margin softmax(AM-softmax)를 사용합니다. 이 방법은 기존의 소프트맥스 함수와는 달리, 로짓과 레이블 사이의 마진(m)을 추가하여 손실을 계산합니다.\n",
    "이렇게 계산된 A-softmax 손실은 클래스 간의 거리를 더 잘 보존하는 특징을 가지고 있어, 분류 모델의 성능 향상에 기여합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac7e83",
   "metadata": {},
   "source": [
    "그림에서 얼굴이 있는 영역을 알아낸다. (face location)\n",
    "얼굴 영역에서 눈, 코, 입 등 68개의 주요 좌표를 추출한다. (facial landmarks 추출)\n",
    "68개의 좌표를 128개의 숫자로 변환한다. (face encoding) 예시임)\n",
    "xw는 입력 x와 가중치 행렬 w의 곱으로 계산된 점수이며, w는 각 클래스에 해당하는 점수를 계산하는 가중치를 나타냅니다. logits 변수는 A-softmax 손실 함수에서 출력으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac12393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다시 시행하기 전에 코드실행\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f045d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10460\\2992277142.py:273: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  output=tf.layers.dense(inputs=input,units=512)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matlab_cp2tform import get_similarity_transform_for_cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt1\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "import math\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np   \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "losslist=[]\n",
    "acclist=[]\n",
    "epochlist=[]\n",
    "elist = []\n",
    "\n",
    "def prelu(_x):\n",
    "    alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                       initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=tf.float32)\n",
    "    pos = tf.nn.relu(_x)\n",
    "    neg = alphas * (_x - abs(_x)) * 0.5\n",
    "    return pos+neg\n",
    "    \n",
    "def alignment(src_img,src_pts):   #얼굴 정렬\n",
    "    ref_pts = [ [30.2946, 51.6963],[65.5318, 51.5014],\n",
    "        [48.0252, 71.7366],[33.5493, 92.3655],[62.7299, 92.2041] ]\n",
    "    crop_size = (96, 112)\n",
    "    src_pts = np.array(src_pts).reshape(5,2)\n",
    "\n",
    "    s = np.array(src_pts).astype(np.float32)\n",
    "    r = np.array(ref_pts).astype(np.float32)\n",
    "\n",
    "    tfm = get_similarity_transform_for_cv2(s, r)\n",
    "    face_img = cv2.warpAffine(src_img, tfm, crop_size)\n",
    "    return face_img\n",
    "\n",
    "\n",
    "def get_batch(step,bz):\n",
    "    shuffle(idx)\n",
    "    x=flist[idx[step*bz:(step+1)*bz]]\n",
    "    y=label[idx[step*bz:(step+1)*bz]]\n",
    "    resultx=[]\n",
    "    for ix in x:\n",
    "        img=plt.imread(ix[0])\n",
    "        tmp = detector.detect_faces(img)[0]['keypoints']\n",
    "        landmark = []\n",
    "        for t in tmp.items(): #딕셔너리 키&값 얻기\n",
    "            for tt in t[1]: #딕셔너리 값 얻기->left eye위치, right eye위치....\n",
    "                landmark.append(tt) #얼굴 값들 landmark에 저장.\n",
    "        img=alignment(img,landmark) #자른 이미지\n",
    "        resultx.append(img) #결과\n",
    "    resultx=np.array(resultx)\n",
    "    y=y.reshape(bz,)\n",
    "    return resultx, y\n",
    "\n",
    "datapath='C:/Users/Administrator/Desktop/두희 얼굴인식/face_recognize code/face'\n",
    "flist=[]\n",
    "for(dirpath,dirnames,filenames) in os.walk(datapath):\n",
    "    for filename in filenames:\n",
    "        if 'CASIA-WebFace' in dirpath:continue\n",
    "        flist.append(dirpath+'/'+filename)\n",
    "label=[]\n",
    "for f in flist[:10]:\n",
    "    label.append(f.split('/')[-1])\n",
    "classnum=10\n",
    "labelset = list(set(label))\n",
    "for i in range(len(label)):\n",
    "    label[i] = labelset.index(label[i])\n",
    "\n",
    "# sess = tf.Session()\n",
    "# label = sess.run(tf.one_hot(label, classnum))\n",
    "label=np.array(label)\n",
    "\n",
    "label=label.reshape(-1,1)\n",
    "flist = np.array(flist[:10])\n",
    "flist = flist.reshape(-1, 1)\n",
    "idx=[i for i in range(10)]\n",
    "shuffle(idx)\n",
    "\n",
    "def Loss_ASoftmax(x, y, l, num_cls, m = 4, name = 'asoftmax'):\n",
    "\n",
    "    xs = x.get_shape()\n",
    "    w = tf.get_variable(\"asoftmax/W\", [xs[1], num_cls], dtype=tf.float32,\n",
    "            initializer=tf.glorot_uniform_initializer())\n",
    "\n",
    "    eps = 1e-8\n",
    "\n",
    "    xw = tf.matmul(x,w)\n",
    "\n",
    "    if m == 0:\n",
    "        return xw, tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=xw))\n",
    "\n",
    "    w_norm = tf.norm(w, axis = 0) + eps\n",
    "    logits = xw/w_norm\n",
    "\n",
    "    if y is None:\n",
    "        return logits, None\n",
    "\n",
    "    ordinal = tf.constant(list(range(0, xs[0])), tf.int64)\n",
    "    ordinal_y = tf.stack([ordinal, y], axis = 1)\n",
    "\n",
    "    x_norm = tf.norm(x, axis = 1) + eps\n",
    "\n",
    "    sel_logits = tf.gather_nd(logits, ordinal_y)\n",
    "\n",
    "    cos_th = tf.div(sel_logits, x_norm)\n",
    "\n",
    "    if m == 1:\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "                              (labels=y,  logits=logits))\n",
    "\n",
    "    else:\n",
    "\n",
    "        if m == 2:\n",
    "\n",
    "            cos_sign = tf.sign(cos_th)\n",
    "            res = 2*tf.multiply(cos_sign, tf.square(cos_th)) - 1\n",
    "\n",
    "        elif m == 4:\n",
    "\n",
    "            cos_th2 = tf.square(cos_th)\n",
    "            cos_th4 = tf.pow(cos_th, 4)\n",
    "            sign0 = tf.sign(cos_th)\n",
    "            sign3 = tf.multiply(tf.sign(2*cos_th2 - 1), sign0)\n",
    "            sign4 = 2*sign0 + sign3 - 3\n",
    "            res = sign3*(8*cos_th4 - 8*cos_th2 + 1) + sign4\n",
    "        else:\n",
    "            raise ValueError('unsupported value of m')\n",
    "\n",
    "        scaled_logits = tf.multiply(res, x_norm)\n",
    "\n",
    "        f = 1.0/(1.0+l)\n",
    "        ff = 1.0 - f\n",
    "        comb_logits_diff = tf.add(logits, tf.scatter_nd(ordinal_y, tf.subtract(scaled_logits, sel_logits), logits.get_shape()))\n",
    "        updated_logits = ff*logits + f*comb_logits_diff\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=updated_logits))\n",
    "    return logits, loss\n",
    "\n",
    "class SphereFace():\n",
    "    def __init__(self,bz,m=4):\n",
    "        self.class_num=classnum\n",
    "        self.m=m\n",
    "        self.lr=0.01\n",
    "        self.batch=bz\n",
    "        self.x=tf.placeholder(dtype=tf.float32,shape=[self.batch,112,96,3])#[b,112,96,3]\n",
    "        self.y=tf.placeholder(dtype=tf.int64,shape=[self.batch,])\n",
    "        #self.x_t=tf.placeholder(dtype=tf.float32,shape=[10,112,96,3])#[b,112,96,3]\n",
    "        #self.y_t=tf.placeholder(dtype=tf.int64,shape=[10,])\n",
    "        \n",
    "        self.conv1_1=self.add_conv(filter_shape=[3,3,3,64],\n",
    "                                 bias_shape=[64],\n",
    "                                 input=self.x,strides=2,)#[b,56,48,64]\n",
    "      \n",
    "        with tf.variable_scope('relu1_1'):\n",
    "            self.relu1_1=prelu(self.conv1_1)\n",
    "        self.result=self.relu1_1\n",
    "        self.conv1_2=self.add_conv(filter_shape=[3,3,64,64],input=self.result,\n",
    "                                   bias_shape=[64])\n",
    "        \n",
    "        with tf.variable_scope('relu1_2'):\n",
    "            self.relu1_2=prelu(self.conv1_2)\n",
    "        self.conv1_3=self.add_conv(filter_shape=[3,3,64,64],input=self.relu1_2,\n",
    "                                   bias_shape=[64])\n",
    "        with tf.variable_scope('relu1_3'):\n",
    "            self.relu1_3=prelu(self.conv1_3)\n",
    "        self.result+=self.relu1_3\n",
    "\n",
    "        self.conv2_1=self.add_conv(filter_shape=[3,3,64,128]\n",
    "                                   ,bias_shape=[128],input=self.result,strides=2)#[b,28,24,128]\n",
    "        with tf.variable_scope('relu2_1'):\n",
    "            self.relu2_1=prelu(self.conv2_1)\n",
    "        self.result = self.relu2_1\n",
    "        self.conv2_2=self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.relu2_1)\n",
    "        with tf.variable_scope('relu2_2'):\n",
    "            self.relu2_2=prelu(self.conv2_2)\n",
    "        self.conv2_3 = self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.relu2_2)\n",
    "        with tf.variable_scope('relu2_3'):\n",
    "            self.relu2_3 = prelu(self.conv2_3)\n",
    "        self.result+=self.relu2_3\n",
    "\n",
    "        self.conv2_4 = self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.result)\n",
    "        with tf.variable_scope('relu2_4'):\n",
    "            self.relu2_4 = prelu(self.conv2_4)\n",
    "        self.conv2_5 = self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.relu2_4)\n",
    "        with tf.variable_scope('relu2_5'):\n",
    "            self.relu2_5 = prelu(self.conv2_5)\n",
    "        self.result+=self.relu2_5\n",
    "\n",
    "\n",
    "        self.conv3_1 = self.add_conv(filter_shape=[3,3,128,256],bias_shape=[256]\n",
    "                                     ,input=self.result,strides=2) #[b,14,12,256]\n",
    "        with tf.variable_scope('relu3_1'):\n",
    "            self.relu3_1 = prelu(self.conv3_1)\n",
    "        self.result = self.relu3_1\n",
    "        self.conv3_2 = self.add_conv(filter_shape=[3,3,256,256],bias_shape=[256],input=self.relu3_1)\n",
    "        with tf.variable_scope('relu3_2'):\n",
    "            self.relu3_2 = prelu(self.conv3_2)\n",
    "        self.conv3_3 = self.add_conv([3,3,256,256],[256],self.relu3_2)\n",
    "        with tf.variable_scope('relu3_3'):\n",
    "            self.relu3_3 = prelu(self.conv3_3)\n",
    "        self.result+=self.relu3_3\n",
    "\n",
    "        self.conv3_4 = self.add_conv([3,3,256,256],[256],self.result)\n",
    "        with tf.variable_scope('relu3_4'):\n",
    "            self.relu3_4 = prelu(self.conv3_4)\n",
    "        self.conv3_5 = self.add_conv([3,3,256,256],[256],self.relu3_4)\n",
    "        with tf.variable_scope('relu3_5'):\n",
    "            self.relu3_5 = prelu(self.conv3_5)\n",
    "        self.result+=self.relu3_5\n",
    "\n",
    "        self.conv3_6 = self.add_conv([3,3,256,256],[256],self.result)\n",
    "        with tf.variable_scope('relu3_6'):\n",
    "            self.relu3_6 = prelu(self.conv3_6)\n",
    "        self.conv3_7 = self.add_conv([3,3,256,256],[256],self.relu3_6)\n",
    "        with tf.variable_scope('relu3_7'):\n",
    "            self.relu3_7 = prelu(self.conv3_7)\n",
    "        self.result+=self.relu3_7\n",
    "\n",
    "        self.conv3_8 = self.add_conv([3,3,256,256],[256],self.result)\n",
    "        with tf.variable_scope('relu3_8'):\n",
    "            self.relu3_8 = prelu(self.conv3_8)\n",
    "        self.conv3_9 = self.add_conv([3,3,256,256],[256],self.relu3_8)\n",
    "        with tf.variable_scope('relu3_9'):\n",
    "            self.relu3_9 =prelu(self.conv3_9)\n",
    "        self.result+=self.relu3_9\n",
    "\n",
    "        self.conv4_1 = self.add_conv([3,3,256,512],[512],self.result,strides=2) #[b,7,6,512]\n",
    "        with tf.variable_scope('relu4_1'):\n",
    "            self.relu4_1 =prelu(self.conv4_1)\n",
    "        self.result = self.relu4_1\n",
    "        self.conv4_2 = self.add_conv([3,3,512,512],[512],self.relu4_1)\n",
    "        with tf.variable_scope('relu4_2'):\n",
    "            self.relu4_2 =prelu(self.conv4_2)\n",
    "        self.conv4_3 = self.add_conv([3,3,512,512],[512],self.relu4_2)\n",
    "        with tf.variable_scope('relu4_3'):\n",
    "            self.relu4_3 = prelu(self.conv4_3)\n",
    "        self.result+=self.relu4_3\n",
    "\n",
    "        self.poutput=self.add_dense(self.result)\n",
    "        \n",
    "        self.output,self.loss=Loss_ASoftmax(self.poutput,self.y,l=1.0,num_cls=self.class_num,m=4)\n",
    "        self.train_step=tf.train.AdamOptimizer(1e-4).minimize(self.loss)\n",
    "        self.corrects=tf.equal(tf.argmax(self.output,1),self.y) \n",
    "        self.acc=tf.reduce_mean(tf.cast(self.corrects,tf.float32))\n",
    "\n",
    "        self.init=tf.global_variables_initializer()\n",
    "        self.sess=tf.Session()\n",
    "        self.sess.run(self.init)\n",
    "        for i in range(300):\n",
    "            x, y = get_batch(step=0, bz=10)  # 학습 데이터셋에서 무작위로 샘플링한 100개의 데이터로 구성된 'batch'를 가져옴\n",
    "            #x = x/255.0             #정규화\n",
    "            #x, x_test, y, y_test = train_test_split(x,y,test_size=0.3)\n",
    "            self.sess.run(self.train_step, feed_dict={self.x: x, self.y: y})    # placeholder x, y_에 샘플링된 batch_xs, batch_ys를 공급함     \n",
    "        loss= self.sess.run(self.acc, feed_dict={self.x: x, self.y:y})\n",
    "        acc = self.sess.run(self.loss, feed_dict={self.x: x, self.y:y})\n",
    "        print(\"Accuracy\",acc)\n",
    "        print(\"Loss\", loss)\n",
    "        losslist.append(loss)\n",
    "        acclist.append(acc)\n",
    "        #print(\"test accuracy\", self.sess.run(self.acc,feed_dict={self.x_t: x_test, self.y_t: y_test}))\n",
    "        \n",
    "    def add_dense(self,input):\n",
    "        input=tf.reshape(input,[-1,7*6*512])\n",
    "        output=tf.layers.dense(inputs=input,units=512)\n",
    "        return output\n",
    "\n",
    "    def weight_variable(self,shape):\n",
    "        init=tf.truncated_normal(shape=shape,stddev=0.01)\n",
    "        return tf.Variable(init)\n",
    "\n",
    "    def add_conv(self,filter_shape,bias_shape,input,strides=1,padding='SAME'):\n",
    "        w1=self.weight_variable(filter_shape)\n",
    "        b1=self.weight_variable(bias_shape)\n",
    "        return tf.nn.conv2d(input,w1,strides=[1,strides,strides,1],padding=padding)+b1\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "if __name__=='__main__':\n",
    "    bz=10\n",
    "    model=SphereFace(bz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('a_loss.npy',losslist)\n",
    "np.save('a_acc.npy', acclist)\n",
    "plt1.xlabel('epoch')\n",
    "plt1.ylabel('loss&acc')\n",
    "plt_dict={}\n",
    "plt_dict['loss']=losslist\n",
    "plt_dict['acc']=acclist\n",
    "plt_color_array=['blue','gree']\n",
    "proxy=[]\n",
    "legend_array=[]\n",
    "for index,(tmp,lora)in enumerate(plt_dict.items()):\n",
    "    color=plt_color_array[index]\n",
    "    plt1.plot(range(len(epochlist)),epochlist,'-%s'%color[0])\n",
    "    proxy.append(Rectangle((0,0),0,0,facecolor=color))\n",
    "    legend_array.append(tmp)\n",
    "plt1.legend(proxy,legend_array)\n",
    "plt1.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
