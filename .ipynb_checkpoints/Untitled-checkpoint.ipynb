{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cd8ae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matlab_cp2tform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatlab_cp2tform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_similarity_transform_for_cv2\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpylab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt1\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matlab_cp2tform'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matlab_cp2tform import get_similarity_transform_for_cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt1\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "import math\n",
    "from random import shuffle\n",
    "losslist=[]\n",
    "acclist=[]\n",
    "epochlist=[]\n",
    "def Loss_ASoftmax(x, y, l, num_cls, m = 2, name = 'asoftmax'):\n",
    "    '''\n",
    "    x: B x D - data\n",
    "    y: B x 1 - label\n",
    "    l: 1 - lambda\n",
    "    '''\n",
    "    xs = x.get_shape()\n",
    "    w = tf.get_variable(\"asoftmax/W\", [xs[1], num_cls], dtype=tf.float32,\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    eps = 1e-8\n",
    "\n",
    "    xw = tf.matmul(x,w)\n",
    "\n",
    "    if m == 0:\n",
    "        return xw, tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=xw))\n",
    "\n",
    "    w_norm = tf.norm(w, axis = 0) + eps\n",
    "    logits = xw/w_norm\n",
    "\n",
    "    if y is None:\n",
    "        return logits, None\n",
    "\n",
    "    ordinal = tf.constant(list(range(0, xs[0])), tf.int64)\n",
    "    ordinal_y = tf.stack([ordinal, y], axis = 1)\n",
    "\n",
    "    x_norm = tf.norm(x, axis = 1) + eps\n",
    "\n",
    "    sel_logits = tf.gather_nd(logits, ordinal_y)\n",
    "\n",
    "    cos_th = tf.div(sel_logits, x_norm)\n",
    "\n",
    "    if m == 1:\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "                              (labels=y,  logits=logits))\n",
    "\n",
    "    else:\n",
    "\n",
    "        if m == 2:\n",
    "\n",
    "            cos_sign = tf.sign(cos_th)\n",
    "            res = 2*tf.multiply(cos_sign, tf.square(cos_th)) - 1\n",
    "\n",
    "        elif m == 4:\n",
    "\n",
    "            cos_th2 = tf.square(cos_th)\n",
    "            cos_th4 = tf.pow(cos_th, 4)\n",
    "            sign0 = tf.sign(cos_th)\n",
    "            sign3 = tf.multiply(tf.sign(2*cos_th2 - 1), sign0)\n",
    "            sign4 = 2*sign0 + sign3 - 3\n",
    "            res = sign3*(8*cos_th4 - 8*cos_th2 + 1) + sign4\n",
    "        else:\n",
    "            raise ValueError('unsupported value of m')\n",
    "\n",
    "        scaled_logits = tf.multiply(res, x_norm)\n",
    "\n",
    "        f = 1.0/(1.0+l)\n",
    "        ff = 1.0 - f\n",
    "        comb_logits_diff = tf.add(logits, tf.scatter_nd(ordinal_y, tf.subtract(scaled_logits, sel_logits), logits.get_shape()))\n",
    "        updated_logits = ff*logits + f*comb_logits_diff\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=updated_logits))\n",
    "    return logits, loss\n",
    "def prelu(_x):\n",
    "  alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                       initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=tf.float32)\n",
    "  pos = tf.nn.relu(_x)\n",
    "  neg = alphas * (_x - abs(_x)) * 0.5\n",
    "  return pos+neg\n",
    "\n",
    "def alignment(src_img,src_pts):\n",
    "    ref_pts = [ [30.2946, 51.6963],[65.5318, 51.5014],\n",
    "        [48.0252, 71.7366],[33.5493, 92.3655],[62.7299, 92.2041] ]\n",
    "    crop_size = (96, 112)\n",
    "    src_pts = np.array(src_pts).reshape(5,2)\n",
    "\n",
    "    s = np.array(src_pts).astype(np.float32)\n",
    "    r = np.array(ref_pts).astype(np.float32)\n",
    "\n",
    "    tfm = get_similarity_transform_for_cv2(s, r)\n",
    "    face_img = cv2.warpAffine(src_img, tfm, crop_size)\n",
    "    return face_img\n",
    "\n",
    "datapath='/home/scut/dq/PycharmProjects/datasets/lfw'\n",
    "flist=[]\n",
    "for(dirpath,dirnames,filenames) in os.walk(datapath):\n",
    "    for filename in filenames:\n",
    "        if 'CASIA-WebFace' in dirpath:continue\n",
    "        flist.append(dirpath+'/'+filename)\n",
    "label=[]\n",
    "for f in flist:\n",
    "    label.append(f.split('/')[-2])\n",
    "classnum=len(set(label))\n",
    "labelset = list(set(label))\n",
    "for i in range(len(label)):\n",
    "    label[i] = labelset.index(label[i])\n",
    "# sess = tf.Session()\n",
    "# label = sess.run(tf.one_hot(label, classnum))\n",
    "label=np.array(label)\n",
    "label=label.reshape(-1,1)\n",
    "flist = np.array(flist)\n",
    "flist = flist.reshape(-1, 1)\n",
    "idx=[i for i in range(len(flist))]\n",
    "shuffle(idx)\n",
    "\n",
    "def get_batch(step=0,bz=64):\n",
    "    x=flist[idx[step*bz:(step+1)*bz]]\n",
    "    y=label[idx[step*bz:(step+1)*bz]]\n",
    "    resultx=[]\n",
    "    for ix in x:\n",
    "        img=plt.imread(ix[0])\n",
    "        tmp = detector.detect_faces(img)[0]['keypoints']\n",
    "        landmark = []\n",
    "        for t in tmp.items():\n",
    "            for tt in t[1]:\n",
    "                landmark.append(tt)\n",
    "        img=alignment(img,landmark)\n",
    "        resultx.append(img)\n",
    "    resultx=np.array(resultx)\n",
    "    y=y.reshape(bz,)\n",
    "    return resultx,y\n",
    "\n",
    "\n",
    "class SphereFace():\n",
    "    def __init__(self,bz,m=4):\n",
    "        self.class_num=classnum\n",
    "        self.m=m\n",
    "        self.lr=0.01\n",
    "        self.batch=bz\n",
    "        self.x=tf.placeholder(dtype=tf.float32,shape=[self.batch,112,96,3])#[b,112,96,3]\n",
    "        self.y=tf.placeholder(dtype=tf.int64,shape=[self.batch])\n",
    "        self.conv1_1=self.add_conv(filter_shape=[3,3,3,64],\n",
    "                                 bias_shape=[64],\n",
    "                                 input=self.x,strides=2,)#[b,56,48,64]\n",
    "        # self.test=self.conv1_1#[64, 56, 48, 64]\n",
    "        with tf.variable_scope('relu1_1'):\n",
    "            self.relu1_1=prelu(self.conv1_1)\n",
    "        # self.test=self.relu1_1\n",
    "        self.result=self.relu1_1\n",
    "        self.conv1_2=self.add_conv(filter_shape=[3,3,64,64],input=self.result,\n",
    "                                   bias_shape=[64])\n",
    "        # self.test=self.conv1_2\n",
    "        with tf.variable_scope('relu1_2'):\n",
    "            self.relu1_2=prelu(self.conv1_2)\n",
    "        self.conv1_3=self.add_conv(filter_shape=[3,3,64,64],input=self.relu1_2,\n",
    "                                   bias_shape=[64])\n",
    "        with tf.variable_scope('relu1_3'):\n",
    "            self.relu1_3=prelu(self.conv1_3)\n",
    "        self.result+=self.relu1_3\n",
    "\n",
    "        self.conv2_1=self.add_conv(filter_shape=[3,3,64,128]\n",
    "                                   ,bias_shape=[128],input=self.result,strides=2)#[b,28,24,128]\n",
    "        with tf.variable_scope('relu2_1'):\n",
    "            self.relu2_1=prelu(self.conv2_1)\n",
    "        self.result = self.relu2_1\n",
    "        self.conv2_2=self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.relu2_1)\n",
    "        with tf.variable_scope('relu2_2'):\n",
    "            self.relu2_2=prelu(self.conv2_2)\n",
    "        self.conv2_3 = self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.relu2_2)\n",
    "        with tf.variable_scope('relu2_3'):\n",
    "            self.relu2_3 = prelu(self.conv2_3)\n",
    "        self.result+=self.relu2_3\n",
    "\n",
    "        self.conv2_4 = self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.result)\n",
    "        with tf.variable_scope('relu2_4'):\n",
    "            self.relu2_4 = prelu(self.conv2_4)\n",
    "        self.conv2_5 = self.add_conv(filter_shape=[3,3,128,128],bias_shape=[128],input=self.relu2_4)\n",
    "        with tf.variable_scope('relu2_5'):\n",
    "            self.relu2_5 = prelu(self.conv2_5)\n",
    "        self.result+=self.relu2_5\n",
    "        # self.test=self.relu2_5\n",
    "\n",
    "\n",
    "        self.conv3_1 = self.add_conv(filter_shape=[3,3,128,256],bias_shape=[256]\n",
    "                                     ,input=self.result,strides=2) #[b,14,12,256]\n",
    "        with tf.variable_scope('relu3_1'):\n",
    "            self.relu3_1 = prelu(self.conv3_1)\n",
    "        self.result = self.relu3_1\n",
    "        self.conv3_2 = self.add_conv(filter_shape=[3,3,256,256],bias_shape=[256],input=self.relu3_1)\n",
    "        with tf.variable_scope('relu3_2'):\n",
    "            self.relu3_2 = prelu(self.conv3_2)\n",
    "        self.conv3_3 = self.add_conv([3,3,256,256],[256],self.relu3_2)\n",
    "        with tf.variable_scope('relu3_3'):\n",
    "            self.relu3_3 = prelu(self.conv3_3)\n",
    "        self.result+=self.relu3_3\n",
    "\n",
    "        self.conv3_4 = self.add_conv([3,3,256,256],[256],self.result)\n",
    "        with tf.variable_scope('relu3_4'):\n",
    "            self.relu3_4 = prelu(self.conv3_4)\n",
    "        self.conv3_5 = self.add_conv([3,3,256,256],[256],self.relu3_4)\n",
    "        with tf.variable_scope('relu3_5'):\n",
    "            self.relu3_5 = prelu(self.conv3_5)\n",
    "        self.result+=self.relu3_5\n",
    "\n",
    "        self.conv3_6 = self.add_conv([3,3,256,256],[256],self.result)\n",
    "        with tf.variable_scope('relu3_6'):\n",
    "            self.relu3_6 = prelu(self.conv3_6)\n",
    "        self.conv3_7 = self.add_conv([3,3,256,256],[256],self.relu3_6)\n",
    "        with tf.variable_scope('relu3_7'):\n",
    "            self.relu3_7 = prelu(self.conv3_7)\n",
    "        self.result+=self.relu3_7\n",
    "\n",
    "        self.conv3_8 = self.add_conv([3,3,256,256],[256],self.result)\n",
    "        with tf.variable_scope('relu3_8'):\n",
    "            self.relu3_8 = prelu(self.conv3_8)\n",
    "        self.conv3_9 = self.add_conv([3,3,256,256],[256],self.relu3_8)\n",
    "        with tf.variable_scope('relu3_9'):\n",
    "            self.relu3_9 =prelu(self.conv3_9)\n",
    "        # self.test=self.relu3_9\n",
    "        self.result+=self.relu3_9\n",
    "\n",
    "        self.conv4_1 = self.add_conv([3,3,256,512],[512],self.result,strides=2) #[b,7,6,512]\n",
    "        with tf.variable_scope('relu4_1'):\n",
    "            self.relu4_1 =prelu(self.conv4_1)\n",
    "        self.result = self.relu4_1\n",
    "        self.conv4_2 = self.add_conv([3,3,512,512],[512],self.relu4_1)\n",
    "        with tf.variable_scope('relu4_2'):\n",
    "            self.relu4_2 =prelu(self.conv4_2)\n",
    "        self.conv4_3 = self.add_conv([3,3,512,512],[512],self.relu4_2)\n",
    "        with tf.variable_scope('relu4_3'):\n",
    "            self.relu4_3 = prelu(self.conv4_3)\n",
    "        self.result+=self.relu4_3\n",
    "\n",
    "        self.poutput=self.add_dense(self.result)\n",
    "        # if(self.m==1):\n",
    "        #     self.output=tf.nn.softmax(self.poutput)\n",
    "        #     self.loss=tf.reduce_mean(-tf.reduce_sum(self.y*tf.log(self.output+1e-10)))\n",
    "        # else:\n",
    "        self.output,self.loss=Loss_ASoftmax(self.poutput,self.y,l=1.0,num_cls=self.class_num,m=self.m)\n",
    "        self.train_step=tf.train.AdamOptimizer(1e-4).minimize(self.loss)\n",
    "        corrects=tf.equal(tf.argmax(self.output,1),self.y)\n",
    "        self.acc=tf.reduce_mean(tf.cast(corrects,tf.float32))\n",
    "\n",
    "        self.test=tf.argmax(self.output,1)\n",
    "\n",
    "        self.init=tf.global_variables_initializer()\n",
    "        self.sess=tf.Session()\n",
    "        self.sess.run(self.init)\n",
    "    def add_dense(self,input):\n",
    "        input=tf.reshape(input,[-1,7*6*512])\n",
    "        output=tf.layers.dense(inputs=input,units=512)\n",
    "        return output\n",
    "\n",
    "    def weight_variable(self,shape):\n",
    "        init=tf.truncated_normal(shape=shape,stddev=0.01)\n",
    "        return tf.Variable(init)\n",
    "\n",
    "    def add_conv(self,filter_shape,bias_shape,input,strides=1,padding='SAME'):\n",
    "        w1=self.weight_variable(filter_shape)\n",
    "        b1=self.weight_variable(bias_shape)\n",
    "        return tf.nn.conv2d(input,w1,strides=[1,strides,strides,1],padding=padding)+b1\n",
    "    \n",
    "from matplotlib.patches import Rectangle\n",
    "if __name__=='__main__':\n",
    "    bz=64\n",
    "    model=SphereFace(bz)\n",
    "\n",
    "    # x, y = get_batch(step=0, bz=bz)\n",
    "    # test=model.sess.run(model.test , feed_dict={model.x: x, model.y: y})\n",
    "    # print(test)\n",
    "    # print(test.shape)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        epochlist.append(epoch)\n",
    "        print('******epoch%d*******'%(epoch+1))\n",
    "        for i in range(int(len(flist)/bz)):\n",
    "            x, y = get_batch(step=0,bz=bz)\n",
    "            #print(y)\n",
    "            model.sess.run(model.train_step,feed_dict={model.x: x, model.y: y})\n",
    "            # y = model.sess.run(model.y,feed_dict={model.x: x, model.y: y})\n",
    "            # t = model.sess.run(model.output, feed_dict={model.x: x, model.y: y})\n",
    "            # print(y.shape, t.shape)\n",
    "            loss = model.sess.run(model.loss, feed_dict={model.x: x, model.y: y})\n",
    "            acc = model.sess.run(model.acc ,feed_dict={model.x: x, model.y: y})\n",
    "            test=model.sess.run(model.test , feed_dict={model.x: x, model.y: y})\n",
    "            #print(test)\n",
    "            print('step:%d / %d  loss:%f  acc:%f'%(i+1,int(len(flist)/bz),loss,acc))\n",
    "        losslist.append(loss)\n",
    "        acclist.append(acc)\n",
    "    np.save('a_loss.npy',losslist)\n",
    "    np.save('a_acc.npy', acclist)\n",
    "    # plt1.xlabel('epoch')\n",
    "    # plt1.ylabel('loss&acc')\n",
    "    # plt_dict={}\n",
    "    # plt_dict['loss']=losslist\n",
    "    # plt_dict['acc']=acclist\n",
    "    # plt_color_array=['blue','gree']\n",
    "    # proxy=[]\n",
    "    # legend_array=[]\n",
    "    # for index,(tmp,lora)in enumerate(plt_dict.items()):\n",
    "    #     color=plt_color_array[index]\n",
    "    #     plt1.plot(range(len(epochlist)),epochlist,'-%s'%color[0])\n",
    "    #     proxy.append(Rectangle((0,0),0,0,facecolor=color))\n",
    "    #     legend_array.append(tmp)\n",
    "    # plt1.legend(proxy,legend_array)\n",
    "    # plt1.show()\n",
    "    saver=tf.train.Saver()\n",
    "    saver.save(model.sess,'finalmodel.ckpt')\n",
    "\n",
    "#################about 20 epochs to meet a good result#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf80e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
